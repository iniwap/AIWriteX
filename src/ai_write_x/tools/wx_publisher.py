from dataclasses import dataclass
from enum import Enum
from typing import Optional
from datetime import datetime, timedelta
import requests
from io import BytesIO
from http import HTTPStatus
from urllib.parse import urlparse, unquote
from pathlib import PurePosixPath
from dashscope import ImageSynthesis
import os
import mimetypes
import json
import time
import re
from bs4 import BeautifulSoup  # âœ… æ–°å¢ï¼šå¯¼å…¥ BeautifulSoup

from src.ai_write_x.utils import utils
from src.ai_write_x.config.config import Config
from src.ai_write_x.utils import log
from src.ai_write_x.utils.path_manager import PathManager


# ... (PublishStatus, PublishResult ç±»ä¿æŒä¸å˜) ...
class PublishStatus(Enum):
    PENDING = "pending"
    PUBLISHED = "published"
    FAILED = "failed"
    DRAFT = "draft"
    SCHEDULED = "scheduled"


@dataclass
class PublishResult:
    publishId: str
    status: PublishStatus
    publishedAt: datetime
    platform: str
    url: Optional[str] = None


class WeixinPublisher:
    BASE_URL = "https://api.weixin.qq.com/cgi-bin"

    # ... (__init__, is_verified, _ensure_access_token ç­‰æ–¹æ³•ä¿æŒä¸å˜) ...
    def __init__(self, app_id: str, app_secret: str, author: str):
        # è·å–é…ç½®æ•°æ®ï¼Œåªèƒ½ä½¿ç”¨ç¡®å®šçš„é…ç½®ï¼Œå¾®ä¿¡é…ç½®æ˜¯å¾ªç¯å‘å¸ƒçš„ï¼Œéœ€è¦ä¼ é€’
        config = Config.get_instance()

        self.access_token_data = None
        self.app_id = app_id
        self.app_secret = app_secret
        self.author = author
        self.img_api_type = config.img_api_type  # åªæœ‰ä¸€ç§æ¨¡å‹ï¼Œç»Ÿä¸€ä»é…ç½®è¯»å–
        self.img_api_key = config.img_api_key
        self.img_api_model = config.img_api_model

    @property
    def is_verified(self):
        if not hasattr(self, "_is_verified"):
            url = f"{self.BASE_URL}/account/getaccountbasicinfo?access_token={self._ensure_access_token()}"  # noqa 501
            response = requests.get(url, timeout=5)

            try:
                response.raise_for_status()
                data = response.json()
                wx_verify = data.get("wx_verify_info", {})
                self._is_verified = bool(wx_verify.get("qualification_verify", False))
            except (requests.RequestException, ValueError, KeyError):
                self._is_verified = False

        return self._is_verified

    def _ensure_access_token(self):
        # æ£€æŸ¥ç°æœ‰tokenæ˜¯å¦æœ‰æ•ˆ
        if self.access_token_data and self.access_token_data[
            "expires_at"
        ] > datetime.now() + timedelta(
            minutes=1
        ):  # é¢„ç•™1åˆ†é’Ÿä½™é‡
            return self.access_token_data["access_token"]

        # è·å–æ–°token
        url = f"{self.BASE_URL}/token?grant_type=client_credential&appid={self.app_id}&secret={self.app_secret}"  # noqa 501

        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
            access_token = data.get("access_token")
            expires_in = data.get("expires_in")

            if not access_token:
                log.print_log(f"è·å–access_tokenå¤±è´¥: {data}")
                return None

            self.access_token_data = {
                "access_token": access_token,
                "expires_in": expires_in,
                "expires_at": datetime.now() + timedelta(seconds=expires_in),
            }
            return access_token
        except requests.exceptions.RequestException as e:
            log.print_log(f"è·å–å¾®ä¿¡access_tokenå¤±è´¥: {e}")

        return None  # è·å–ä¸åˆ°å°±è¿”å›Noneï¼Œå¤±è´¥äº¤ç»™åé¢çš„æµç¨‹å¤„ç†

    def _upload_draft(self, article, title, digest, media_id):
        token = self._ensure_access_token()
        url = f"{self.BASE_URL}/draft/add?access_token={token}"

        articles = [
            {
                "title": title[:64],  # æ ‡é¢˜é•¿åº¦ä¸èƒ½è¶…è¿‡64
                "author": self.author,
                "digest": digest[:120],
                "content": article,
                "thumb_media_id": media_id,
                "need_open_comment": 1,
                "only_fans_can_comment": 0,
            },
        ]
        ret = None, None
        try:
            data = {"articles": articles}

            headers = {"Content-Type": "application/json"}
            json_data = json.dumps(data, ensure_ascii=False).encode("utf-8")
            response = requests.post(url, data=json_data, headers=headers)
            response.raise_for_status()
            data = response.json()

            if "errcode" in data and data.get("errcode") != 0:
                ret = None, f"ä¸Šä¼ è‰ç¨¿å¤±è´¥: {data.get('errmsg')}"
            elif "media_id" not in data:
                ret = None, "ä¸Šä¼ è‰ç¨¿å¤±è´¥: å“åº”ä¸­ç¼ºå°‘ media_id"
            else:
                ret = {"media_id": data.get("media_id")}, None
        except requests.exceptions.RequestException as e:
            ret = None, f"ä¸Šä¼ å¾®ä¿¡è‰ç¨¿å¤±è´¥: {e}"

        return ret

    def _generate_img_by_ali(self, prompt, size="1024*1024"):
        image_dir = PathManager.get_image_dir()
        img_url = None
        try:
            rsp = ImageSynthesis.call(
                api_key=self.img_api_key,
                model=self.img_api_model,
                prompt=prompt,
                negative_prompt="ä½åˆ†è¾¨ç‡ã€é”™è¯¯ã€æœ€å·®è´¨é‡ã€ä½è´¨é‡ã€æ®‹ç¼ºã€å¤šä½™çš„æ‰‹æŒ‡ã€æ¯”ä¾‹ä¸è‰¯",
                n=1,
                size=size,
            )
            if rsp.status_code == HTTPStatus.OK:
                # å®é™…ä¸Šåªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œä¸ºäº†èŠ‚çº¦ï¼Œä¸åŒæ—¶ç”Ÿæˆå¤šå¼ 
                for result in rsp.output.results:
                    file_name = PurePosixPath(unquote(urlparse(result.url).path)).parts[-1]
                    # æ‹¼æ¥ç»å¯¹è·¯å¾„å’Œæ–‡ä»¶å
                    file_path = os.path.join(image_dir, file_name)
                    with open(file_path, "wb+") as f:
                        f.write(requests.get(result.url).content)
                img_url = rsp.output.results[0].url
            else:
                log.print_log(
                    "sync_call Failed, status_code: %s, code: %s, message: %s"
                    % (rsp.status_code, rsp.code, rsp.message)
                )
        except Exception as e:
            log.print_log(f"_generate_img_by_aliè°ƒç”¨å¤±è´¥: {e}")

        return img_url

    def generate_img(self, prompt, size="1024*1024"):
        img_url = None
        if self.img_api_type == "ali":
            img_url = self._generate_img_by_ali(prompt, size)
        elif self.img_api_type == "picsum":
            image_dir = str(PathManager.get_image_dir())
            width_height = size.split("*")
            download_url = f"https://picsum.photos/{width_height[0]}/{width_height[1]}?random=1"
            img_url = utils.download_and_save_image(download_url, image_dir)

        return img_url

    def upload_image(self, image_url):
        from src.ai_write_x.utils.utils import resolve_image_path  # å¯¼å…¥æ–°å‡½æ•°

        if not image_url:
            return "SwCSRjrdGJNaWioRQUHzgF68BHFkSlb_f5xlTquvsOSA6Yy0ZRjFo0aW9eS3JJu_", None, None

        ret = None, None, None
        try:
            # å…ˆè§£æå›¾ç‰‡è·¯å¾„
            resolved_path = resolve_image_path(image_url)

            if resolved_path.startswith(("http://", "https://")):
                # å¤„ç†ç½‘ç»œå›¾ç‰‡
                image_response = requests.get(resolved_path, stream=True)
                image_response.raise_for_status()
                image_buffer = BytesIO(image_response.content)

                mime_type = image_response.headers.get("Content-Type")
                if not mime_type:
                    mime_type = "image/jpeg"
                file_ext = mimetypes.guess_extension(mime_type)
                file_name = "image" + file_ext if file_ext else "image.jpg"
            else:
                # å¤„ç†æœ¬åœ°å›¾ç‰‡
                if not os.path.exists(resolved_path):
                    ret = None, None, f"æœ¬åœ°å›¾ç‰‡æœªæ‰¾åˆ°: {resolved_path}"
                    return ret

                with open(resolved_path, "rb") as f:
                    image_buffer = BytesIO(f.read())

                mime_type, _ = mimetypes.guess_type(resolved_path)
                if not mime_type:
                    mime_type = "image/jpeg"
                file_name = os.path.basename(resolved_path)

            token = self._ensure_access_token()
            if self.is_verified:
                url = f"{self.BASE_URL}/media/upload?access_token={token}&type=image"
            else:
                url = f"{self.BASE_URL}/material/add_material?access_token={token}&type=image"

            files = {"media": (file_name, image_buffer, mime_type)}
            response = requests.post(url, files=files)
            response.raise_for_status()
            data = response.json()

            if "errcode" in data and data.get("errcode") != 0:
                ret = None, None, f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {data.get('errmsg')}"
            elif "media_id" not in data:
                ret = None, None, "å›¾ç‰‡ä¸Šä¼ å¤±è´¥: å“åº”ä¸­ç¼ºå°‘ media_id"
            else:
                ret = data.get("media_id"), data.get("url"), None

        except requests.exceptions.RequestException as e:
            ret = None, None, f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {e}"

        return ret

    def add_draft(self, article, title, digest, media_id):
        ret = None, None
        try:
            # ä¸Šä¼ è‰ç¨¿
            draft, err_msg = self._upload_draft(article, title, digest, media_id)
            if draft is not None:
                ret = (
                    PublishResult(
                        publishId=draft["media_id"],
                        status=PublishStatus.DRAFT,
                        publishedAt=datetime.now(),
                        platform="wechat",
                        url=f"https://mp.weixin.qq.com/s/{draft['media_id']}",
                    ),
                    None,
                )
            else:
                ret = None, err_msg
        except Exception as e:
            ret = None, f"å¾®ä¿¡æ·»åŠ è‰ç¨¿å¤±è´¥: {e}"

        return ret

    def publish(self, media_id: str):
        """
        å‘å¸ƒè‰ç¨¿ç®±ä¸­çš„å›¾æ–‡ç´ æ

        :param media_id: è¦å‘å¸ƒçš„è‰ç¨¿çš„media_id
        :return: åŒ…å«å‘å¸ƒä»»åŠ¡IDçš„å­—å…¸
        """
        ret = None, None
        url = f"{self.BASE_URL}/freepublish/submit"
        params = {"access_token": self._ensure_access_token()}
        data = {"media_id": media_id}

        try:
            response = requests.post(url, params=params, json=data)
            response.raise_for_status()
            result = response.json()

            if "errcode" in result and result.get("errcode") != 0:
                ret = None, f"è‰ç¨¿å‘å¸ƒå¤±è´¥: {result.get('errmsg')}"
            elif "publish_id" not in result:
                ret = None, "è‰ç¨¿å‘å¸ƒå¤±è´¥: å“åº”ä¸­ç¼ºå°‘ publish_id"
            else:
                ret = (
                    PublishResult(
                        publishId=result.get("publish_id"),
                        status=PublishStatus.PUBLISHED,
                        publishedAt=datetime.now(),
                        platform="wechat",
                        url="",  # éœ€è¦é€šè¿‡è½®è¯¢è·å–
                    ),
                    None,
                )
        except Exception as e:
            ret = None, f"å‘å¸ƒè‰ç¨¿æ–‡ç« å¤±è´¥ï¼š{e}"

        return ret

    # è½®è¯¢è·å–æ–‡ç« é“¾æ¥
    def poll_article_url(self, publish_id, max_retries=10, interval=2):
        url = f"{self.BASE_URL}/freepublish/get?access_token={self._ensure_access_token()}"
        params = {"publish_id": publish_id}

        for _ in range(max_retries):
            response = requests.post(url, json=params).json()
            if response.get("article_id"):
                return response.get("article_detail")["item"][0]["article_url"]

            time.sleep(interval)

        return None

    # ---------------------ä»¥ä¸‹æ¥å£éœ€è¦å¾®ä¿¡è®¤è¯[ä¸ªäººç”¨æˆ·ä¸å¯ç”¨]-------------------------
    # å•ç‹¬å‘å¸ƒåªèƒ½é€šè¿‡ç»‘å®šåˆ°èœå•çš„å½¢å¼è®¿é—®åˆ°ï¼Œæ— æ³•æ˜¾ç¤ºåˆ°å…¬ä¼—å·æ–‡ç« åˆ—è¡¨
    def create_menu(self, article_url):
        ret = ""
        menu_data = {
            "button": [
                {
                    "type": "view",
                    "name": "æœ€æ–°æ–‡ç« ",
                    "url": article_url,
                }
            ]
        }
        menu_url = f"{self.BASE_URL}/menu/create?access_token={self._ensure_access_token()}"
        try:
            result = requests.post(menu_url, json=menu_data).json()
            if "errcode" in result and result.get("errcode") != 0:
                ret = f"åˆ›å»ºèœå•å¤±è´¥: {result.get('errmsg')}"
        except Exception as e:
            ret = f"åˆ›å»ºèœå•å¤±è´¥:{e}"

        return ret

    # ä¸Šä¼ å›¾æ–‡æ¶ˆæ¯ç´ æã€è®¢é˜…å·ä¸æœåŠ¡å·è®¤è¯åå‡å¯ç”¨ã€‘
    def media_uploadnews(self, article, title, digest, media_id):
        token = self._ensure_access_token()
        url = f"{self.BASE_URL}/media/uploadnews?access_token={token}"

        articles = [
            {
                "thumb_media_id": media_id,
                "author": self.author,
                "title": title[:64],
                "content": article,
                "digest": digest[:120],
                "show_cover_pic": 1,
                "need_open_comment": 1,
                "only_fans_can_comment": 0,
            }
        ]

        ret = None, None
        try:
            data = {"articles": articles}
            headers = {"Content-Type": "application/json"}
            json_data = json.dumps(data, ensure_ascii=False).encode("utf-8")
            response = requests.post(url, data=json_data, headers=headers)
            response.raise_for_status()
            result = response.json()

            if "errcode" in result and result.get("errcode") != 0:
                ret = None, f"ä¸Šä¼ å›¾æ–‡ç´ æå¤±è´¥: {result.get('errmsg')}"
            elif "media_id" not in result:
                ret = None, "ä¸Šä¼ å›¾æ–‡ç´ æå¤±è´¥: å“åº”ä¸­ç¼ºå°‘ media_id"
            else:
                ret = result.get("media_id"), None
        except requests.exceptions.RequestException as e:
            ret = None, f"ä¸Šä¼ å¾®ä¿¡å›¾æ–‡ç´ æå¤±è´¥: {e}"

        return ret

    # æ ¹æ®æ ‡ç­¾è¿›è¡Œç¾¤å‘ã€è®¢é˜…å·ä¸æœåŠ¡å·è®¤è¯åå‡å¯ç”¨ã€‘
    def message_mass_sendall(self, media_id, is_to_all=True, tag_id=0):
        ret = None

        if is_to_all:
            data_filter = {
                "is_to_all": is_to_all,
            }
        else:
            if tag_id == 0:
                return "æ ¹æ®æ ‡ç­¾è¿›è¡Œç¾¤å‘å¤±è´¥ï¼šæœªå‹¾é€‰ç¾¤å‘ï¼Œä¸”tag_id=0æ— æ•ˆ"

            data_filter = {
                "is_to_all": is_to_all,
                "tag_id": tag_id,
            }
        data = {
            "filter": data_filter,
            "mpnews": {"media_id": media_id},
            "msgtype": "mpnews",
            "send_ignore_reprint": 1,
        }
        url = f"{self.BASE_URL}/message/mass/sendall?access_token={self._ensure_access_token()}"

        try:
            result = requests.post(url, json=data).json()
            if "errcode" in result and result.get("errcode") != 0:
                ret = f"æ ¹æ®æ ‡ç­¾è¿›è¡Œç¾¤å‘å¤±è´¥: {result.get('errmsg')}"
        except Exception as e:
            ret = f"ç¾¤å‘æ¶ˆæ¯å¤±è´¥ï¼š{e}"

        return ret

    def _replace_div_with_section(self, content):
        """
        å¼ºåˆ¶å°†æ‰€æœ‰ <div> æ ‡ç­¾è½¬æ¢ä¸º <section>
        å¾®ä¿¡å…¬ä¼—å·åå°å¯¹ section çš„å…¼å®¹æ€§æ›´å¥½ï¼Œä¸”èƒ½é¿å…éƒ¨åˆ† div æ ·å¼ä¸¢å¤±é—®é¢˜ã€‚
        """
        if not content:
            return ""

        try:
            # ä½¿ç”¨ html.parser è§£æ
            soup = BeautifulSoup(content, "html.parser")

            # æŸ¥æ‰¾æ‰€æœ‰ div æ ‡ç­¾å¹¶ç›´æ¥ä¿®æ”¹å…¶ name å±æ€§
            # è¿™æ¯”æ­£åˆ™æ›¿æ¢æ›´å®‰å…¨ï¼Œä¸ä¼šè¯¯ä¼¤æ–‡æœ¬å†…å®¹
            for tag in soup.find_all("div"):
                tag.name = "section"

            # åªè¦æŠŠ tag.name æ”¹äº†ï¼Œè¾“å‡ºæ—¶å°±ä¼šå˜æˆ <section>...</section>
            return str(soup)

        except Exception as e:
            log.print_log(f"Divè½¬Sectionå¤±è´¥(bs4): {e}")
            return content

    def _compress_html(self, content, use_compress=True):
        """
        æ™ºèƒ½å‹ç¼©HTMLï¼ˆæ­£åˆ™ç‰ˆï¼‰ï¼š
        åªè´Ÿè´£â€œæ¸…æ´—â€å·¥ä½œï¼šå»é™¤æ¢è¡Œç¬¦å’Œæ ‡ç­¾é—´çš„å¹½çµç©ºæ ¼ï¼Œé˜²æ­¢å¾®ä¿¡æ’ç‰ˆé”™ä¹±ã€‚
        """
        if not use_compress or not content:
            return content

        # 1. ç§»é™¤æ³¨é‡Š
        content = re.sub(r"<!--.*?-->", "", content, flags=re.DOTALL)

        # 2. æ ¸å¿ƒä¿®å¤ï¼šåªç§»é™¤â€œæ ‡ç­¾ > åçš„ã€æ¢è¡Œç¬¦+ç¼©è¿›ç©ºæ ¼ã€‘â€
        # é€»è¾‘ï¼šç¼–è¾‘å™¨é‡Œçš„æ¢è¡Œ+ç¼©è¿›æ˜¯å¤šä½™çš„ï¼Œåˆ æ‰ã€‚
        content = re.sub(r">[\n\r]+\s*", ">", content)

        # 3. ç§»é™¤æ ‡ç­¾ç»“å°¾ < å‰é¢çš„æ¢è¡Œå’Œç¼©è¿›
        content = re.sub(r"\s+<", "<", content)

        # 4. ç§»é™¤æ ‡ç­¾ä¹‹é—´çš„çº¯ç©ºç™½
        content = re.sub(r">\s+<", "><", content)

        # 5. æ¸…ç†å‰©ä½™æ¢è¡Œç¬¦
        content = content.replace("\n", "").replace("\r", "")

        return content

    def _inject_indent(self, content):
        """
        æ™ºèƒ½æ³¨å…¥é¦–è¡Œç¼©è¿›ï¼ˆBS4 ç»ˆæç‰ˆï¼‰ï¼š
        ç»™æ­£æ–‡æ®µè½æ·»åŠ  text-indent: 2emã€‚
        å‡çº§ï¼š
        1. å‘ä¸ŠæŸ¥æ‰¾5å±‚ç¥–å…ˆï¼Œå½»åº•æ’é™¤å¡ç‰‡ã€æç¤ºæ¡†ã€åµŒå¥—å¸ƒå±€ã€‚
        2. å¢åŠ  box-shadow (é˜´å½±) æ£€æµ‹ï¼Œè¿™æ˜¯è¯†åˆ«å¡ç‰‡çš„å…³é”®ã€‚
        3. æ’é™¤çŸ­æ–‡æœ¬å’Œç‰¹æ®Šç¬¦å·å¼€å¤´çš„æ®µè½ï¼ˆå¦‚æ³¨é‡Šã€åˆ—è¡¨ï¼‰ã€‚
        """
        if not content:
            return ""

        try:
            soup = BeautifulSoup(content, "html.parser")

            for p in soup.find_all("p"):
                # --- æ–‡æœ¬å†…å®¹æ£€æŸ¥ (æ–°åŠŸèƒ½) ---
                text = p.get_text().strip()

                # 1. ç©ºæ®µè½æˆ–æçŸ­æ®µè½è·³è¿‡ (é€šå¸¸æ˜¯æ ‡é¢˜ã€æŒ‰é’®æ–‡å­—æˆ–è£…é¥°æ€§æ–‡å­—)
                if not text or len(text) < 30:
                    continue

                # 2. ç‰¹æ®Šç¬¦å·å¼€å¤´è·³è¿‡ (ä»£ç æ³¨é‡Šã€ä¼ªåˆ—è¡¨ã€å¼•ç”¨)
                # æ‚¨çš„æˆªå›¾ä¸­ "//" å¼€å¤´çš„æ³¨é‡Šå°±ä¼šåœ¨è¿™é‡Œè¢«è±å…
                if text.startswith(
                    ("/", "â—", "-", ">", "â€¢", "*", "1.", "2.", "3.", "4.", "5.", "#")
                ):
                    continue

                should_skip = False

                # --- ğŸ›¡ï¸ æ·±åº¦è±å…æ‰«æ (æŸ¥è‡ªå·± + å¾€ä¸ŠæŸ¥5ä»£) ---
                # æ£€æŸ¥åˆ—è¡¨åŒ…å«ï¼šå½“å‰æ ‡ç­¾ pï¼Œä»¥åŠå®ƒçš„çˆ¶çº§...
                check_list = [p] + list(p.parents)[:5]

                for node in check_list:
                    if not hasattr(node, "name"):
                        continue

                    # 1.ã€ç»“æ„è±å…ã€‘åˆ—è¡¨ã€å¼•ç”¨ã€è¡¨æ ¼ã€ä»£ç å—ã€æŒ‰é’®
                    if node.name in [
                        "li",
                        "blockquote",
                        "th",
                        "td",
                        "figcaption",
                        "pre",
                        "code",
                        "dt",
                        "dd",
                        "button",
                        "a",
                    ]:
                        should_skip = True
                        break

                    # è·å–æ ·å¼
                    style = node.get("style", "").lower()

                    # 2.ã€å¯¹é½è±å…ã€‘
                    if "text-align" in style and ("center" in style or "right" in style):
                        should_skip = True
                        break

                    # 3.ã€å¸ƒå±€è±å…ã€‘Flex / Grid / Inline-Block
                    if "display" in style and (
                        "flex" in style or "grid" in style or "inline-block" in style
                    ):
                        should_skip = True
                        break

                    # 4.ã€è£…é¥°è±å…ã€‘æœ‰èƒŒæ™¯è‰²ã€è¾¹æ¡†ã€**é˜´å½±(å…³é”®)**
                    # åªè¦ç¥–å…ˆé‡Œæœ‰ box-shadowï¼Œè¯´æ˜è¿™æ˜¯ä¸ªå¡ç‰‡ï¼Œåšå†³ä¸ç¼©è¿›
                    if "background" in style or "border" in style or "box-shadow" in style:
                        should_skip = True
                        break

                if should_skip:
                    continue

                # 5.ã€è‡ªèº«æ£€æŸ¥ã€‘
                p_style = p.get("style", "").lower()
                if "text-indent" in p_style:
                    continue

                # --- æ³¨å…¥æ ·å¼ ---
                current_style = p.get("style", "")
                new_style = f"text-indent: 2em; {current_style}".strip()
                p["style"] = new_style

            return str(soup)

        except Exception as e:
            log.print_log(f"HTMLæ ·å¼æ³¨å…¥å¤±è´¥(bs4): {e}ï¼Œå°†ä½¿ç”¨åŸå§‹æ’ç‰ˆ")
            return content


def pub2wx(title, digest, article, appid, appsecret, author, cover_path=None):
    publisher = WeixinPublisher(appid, appsecret, author)
    config = Config.get_instance()

    # 1. ç»“æ„æ ‡å‡†åŒ–ï¼šå¼ºåˆ¶ Div -> Section
    # è¿™æ˜¯å¤„ç†çš„ç¬¬ä¸€æ­¥ï¼Œç¡®ä¿æ‰€æœ‰å®¹å™¨éƒ½æ˜¯å¾®ä¿¡å‹å¥½çš„ <section>
    article = publisher._replace_div_with_section(article)

    # 2. æ ·å¼æ³¨å…¥ï¼šé¦–è¡Œç¼©è¿›
    # åœ¨ div å˜æˆ section ä¹‹åå†æ³¨å…¥æ ·å¼ï¼Œè™½ç„¶ä¸»è¦é’ˆå¯¹ p æ ‡ç­¾ï¼Œä½†å±‚çº§ç»“æ„å¯èƒ½å˜äº†ï¼Œæ‰€ä»¥æ”¾åœ¨ç»“æ„è°ƒæ•´å
    article = publisher._inject_indent(article)

    # 3. å†å¤„ç†æ­£æ–‡å›¾ç‰‡URLæ›¿æ¢ (bs4 å¤„ç†åçš„ html ç»“æ„æ ‡å‡†ï¼Œåˆ©äºæ­£åˆ™æå–)
    cropped_image_path = ""
    final_image_path = None  # æœ€ç»ˆè¦ä¸Šä¼ çš„å›¾ç‰‡è·¯å¾„

    if cover_path:
        resolved_cover_path = utils.resolve_image_path(cover_path)
        cropped_image_path = utils.crop_cover_image(resolved_cover_path, (900, 384))

        if cropped_image_path:
            final_image_path = cropped_image_path
        else:
            final_image_path = resolved_cover_path
    else:
        # è‡ªåŠ¨ç”Ÿæˆå°é¢
        image_url = publisher.generate_img(
            "ä¸»é¢˜:" + title.split("|")[-1] + ",å†…å®¹:" + digest,
            "900*384",
        )

        if image_url is None:
            log.print_log("ç”Ÿæˆå›¾ç‰‡å‡ºé”™,ä½¿ç”¨é»˜è®¤å›¾ç‰‡")
            default_image = utils.get_res_path(
                os.path.join("UI", "bg.png"), os.path.dirname(__file__) + "/../gui/"
            )
            final_image_path = utils.resolve_image_path(default_image)
        else:
            final_image_path = utils.resolve_image_path(image_url)

    # å°é¢å›¾ç‰‡ä¸Šä¼ 
    media_id, _, err_msg = publisher.upload_image(final_image_path)

    # å¦‚æœä½¿ç”¨äº†ä¸´æ—¶è£å‰ªæ–‡ä»¶ï¼Œä¸Šä¼ ååˆ é™¤
    if cover_path and cropped_image_path and cropped_image_path != cover_path:
        try:
            os.remove(cropped_image_path)
        except Exception:
            pass

    if media_id is None:
        return f"å°é¢{err_msg}ï¼Œæ— æ³•å‘å¸ƒæ–‡ç« ", article, False

    # è¿™é‡Œéœ€è¦å°†æ–‡ç« ä¸­çš„å›¾ç‰‡urlæ›¿æ¢ä¸ºä¸Šä¼ åˆ°å¾®ä¿¡è¿”å›çš„å›¾ç‰‡url
    try:
        image_urls = utils.extract_image_urls(article)
        for image_url in image_urls:
            # å…ˆè§£æå›¾ç‰‡è·¯å¾„
            resolved_path = utils.resolve_image_path(image_url)

            # åˆ¤æ–­è§£æåçš„è·¯å¾„ç±»å‹
            if utils.is_local_path(resolved_path):
                # æœ¬åœ°è·¯å¾„å¤„ç†
                if os.path.exists(resolved_path):
                    _, url, err_msg = publisher.upload_image(resolved_path)
                    if url:
                        article = article.replace(image_url, url)
                    else:
                        log.print_log(f"æœ¬åœ°å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {image_url}, é”™è¯¯: {err_msg}")
                else:
                    log.print_log(f"æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {resolved_path}")
            else:
                # ç½‘ç»œURLå¤„ç†
                local_filename = utils.download_and_save_image(
                    resolved_path,
                    str(PathManager.get_image_dir()),
                )
                if local_filename:
                    _, url, err_msg = publisher.upload_image(local_filename)
                    if url:
                        article = article.replace(image_url, url)
                    else:
                        log.print_log(f"ç½‘ç»œå›¾ç‰‡ä¸Šä¼ å¤±è´¥: {image_url}, é”™è¯¯: {err_msg}")
                else:
                    log.print_log(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥:{image_url}")
    except Exception as e:
        log.print_log(f"ä¸Šä¼ é…å›¾å‡ºé”™,å½±å“é˜…è¯»,å¯ç»§ç»­å‘å¸ƒæ–‡ç« :{e}")

    # 4. åœ¨ä¸Šä¼ ç»™å¾®ä¿¡å‰ï¼ŒæŠŠæ‰€æœ‰æ¢è¡Œç¬¦ã€ç¼©è¿›ç©ºæ ¼ç»Ÿç»Ÿå¹²æ‰ï¼Œè§£å†³â€œå¹½çµç©ºéš™â€
    article = publisher._compress_html(article)

    # è´¦å·æ˜¯å¦è®¤è¯
    if not publisher.is_verified:
        add_draft_result, err_msg = publisher.add_draft(article, title, digest, media_id)
        if add_draft_result is None:
            # æ·»åŠ è‰ç¨¿å¤±è´¥ï¼Œä¸å†ç»§ç»­æ‰§è¡Œ
            return f"{err_msg}ï¼Œæ— æ³•å‘å¸ƒæ–‡ç« ", article, False

        publish_result, err_msg = publisher.publish(add_draft_result.publishId)
        if publish_result is None:
            if "api unauthorized" in err_msg:  # type: ignore
                return (
                    "è‡ªåŠ¨å‘å¸ƒå¤±è´¥ï¼Œã€è‡ª2025å¹´7æœˆ15æ—¥èµ·ï¼Œä¸ªäººä¸»ä½“è´¦å·ã€æœªè®¤è¯ä¼ä¸šè´¦å·åŠä¸æ”¯æŒè®¤è¯çš„è´¦å·çš„å‘å¸ƒæƒé™è¢«å›æ”¶ï¼Œéœ€åˆ°å…¬ä¼—å·ç®¡ç†åå°->è‰ç¨¿ç®±->å‘è¡¨ã€‘",
                    article,
                    True,  # æ­¤ç±»ç›®å‰è®¤ä¸ºæ˜¯å‘å¸ƒæˆåŠŸ
                )
            else:
                return f"{err_msg}ï¼Œæ— æ³•ç»§ç»­å‘å¸ƒæ–‡ç« ", article, False
    else:
        # æ˜¾ç¤ºåˆ°åˆ—è¡¨
        media_id, ret = publisher.media_uploadnews(article, title, digest, media_id)
        if media_id is None:
            if "api unauthorized" in ret:  # type: ignore
                return (
                    "è´¦å·è™½è®¤è¯ï¼ˆéä¼ä¸šè´¦å·ï¼‰ï¼Œä½†æ— å‘å¸ƒæƒé™ï¼Œå‘å¸ƒå¤±è´¥ï¼Œæ— æ³•è‡ªåŠ¨å‘å¸ƒæ–‡ç« ",
                    article,
                    False,
                )
            else:
                return f"{ret}ï¼Œæ— æ³•æ˜¾ç¤ºåˆ°å…¬ä¼—å·æ–‡ç« åˆ—è¡¨ï¼ˆå…¬ä¼—å·æœªè®¤è¯ï¼‰", article, False

        """
        article_url = publisher.poll_article_url(publish_result.publishId)
        if article_url is not None:
            # è¯¥æ¥å£éœ€è¦è®¤è¯,å°†æ–‡ç« æ·»åŠ åˆ°èœå•ä¸­å»ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡èœå•â€œæœ€æ–°æ–‡ç« â€è·å–åˆ°
            ret = publisher.create_menu(article_url)
            if not ret:
                log.print_log(f"{ret}ï¼ˆå…¬ä¼—å·æœªè®¤è¯ï¼Œå‘å¸ƒå·²æˆåŠŸï¼‰")
        else:
            log.print_log("æ— æ³•è·å–åˆ°æ–‡ç« URLï¼Œæ— æ³•åˆ›å»ºèœå•ï¼ˆå¯å¿½ç•¥ï¼Œå‘å¸ƒå·²æˆåŠŸï¼‰")
        """

        # æ˜¯å¦è®¾ç½®ä¸ºç¾¤å‘
        """
        å¾®ä¿¡å®˜æ–¹è¯´æ˜ï¼šhttps://developers.weixin.qq.com/doc/service/guide/product/message/Batch_Sends.html

        å…³äºç¾¤å‘æ—¶è®¾ç½® is_to_all ä¸º true ä½¿å…¶è¿›å…¥æœåŠ¡å·åœ¨å¾®ä¿¡å®¢æˆ·ç«¯çš„å†å²æ¶ˆæ¯åˆ—è¡¨çš„è¯´æ˜ï¼š
        è®¾ç½® is_to_all ä¸º true ä¸”æˆåŠŸç¾¤å‘ï¼Œä¼šä½¿å¾—æ­¤æ¬¡ç¾¤å‘è¿›å…¥å†å²æ¶ˆæ¯åˆ—è¡¨ã€‚
        ä¸ºé˜²æ­¢å¼‚å¸¸ï¼Œè®¤è¯æœåŠ¡å·åœ¨ä¸€å¤©å†…ï¼Œåªèƒ½è®¾ç½® is_to_all ä¸º true ä¸”æˆåŠŸç¾¤å‘ä¸€æ¬¡ï¼Œæˆ–è€…åœ¨å…¬ä¼—å¹³å°å®˜ç½‘ç¾¤å‘ä¸€æ¬¡ã€‚ä»¥é¿å…ä¸€å¤©å†…æœ‰2æ¡ç¾¤å‘è¿›å…¥å†å²æ¶ˆæ¯åˆ—è¡¨ã€‚
        ç±»ä¼¼åœ°ï¼ŒæœåŠ¡å·åœ¨ä¸€ä¸ªæœˆå†…ï¼Œè®¾ç½® is_to_all ä¸º true ä¸”æˆåŠŸç¾¤å‘çš„æ¬¡æ•°ï¼ŒåŠ ä¸Šå…¬ä¼—å¹³å°å®˜ç½‘ç¾¤å‘çš„æ¬¡æ•°ï¼Œæœ€å¤šåªèƒ½æ˜¯4æ¬¡ã€‚
        æœåŠ¡å·è®¾ç½® is_to_all ä¸º false æ—¶æ˜¯å¯ä»¥å¤šæ¬¡ç¾¤å‘çš„ï¼Œä½†æ¯ä¸ªç”¨æˆ·ä¸€ä¸ªæœˆå†…åªä¼šæ”¶åˆ°æœ€å¤š4æ¡ï¼Œä¸”è¿™äº›ç¾¤å‘ä¸ä¼šè¿›å…¥å†å²æ¶ˆæ¯åˆ—è¡¨ã€‚
        """
        if config.get_call_sendall_by_appid(appid):
            ret = publisher.message_mass_sendall(
                media_id,
                config.get_sendall_by_appid(appid),
                config.get_tagid_by_appid(appid),
            )
            if ret is not None:
                if "api unauthorized" in ret:
                    return (
                        "æ²¡æœ‰ç¾¤å‘æƒé™ï¼Œæ— æ³•æ˜¾ç¤ºåˆ°å…¬ä¼—å·æ–‡ç« åˆ—è¡¨ï¼ˆå‘å¸ƒå·²æˆåŠŸï¼‰",
                        article,
                        True,
                    )
                else:
                    return (
                        f"{ret}ï¼Œæ— æ³•æ˜¾ç¤ºåˆ°å…¬ä¼—å·æ–‡ç« åˆ—è¡¨ï¼ˆå‘å¸ƒå·²æˆåŠŸï¼‰",
                        article,
                        True,
                    )

    return "æˆåŠŸå‘å¸ƒæ–‡ç« åˆ°å¾®ä¿¡å…¬ä¼—å·", article, True
